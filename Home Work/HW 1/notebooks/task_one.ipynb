{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1da2SfM2_O9"
      },
      "source": [
        "# Домашняя работа часть 1  (20 баллов): анализ падения точности LLM после квантизации и спарсификации\n",
        "\n",
        "\n",
        "В этом задании вам предстоит проанализировать популярные методы компресии больших языковых моделей, среди которых QUIK, Wanda и SparseGPT, комбинация SparseGPT и GPTQ\n",
        "\n",
        "В качестве языковой модели будет использована модель opt-350m.\n",
        "\n",
        "Результат задания: Построить 8 графиков (по одному для каждого из 4 методов компресии и двух тестовых датасетов) зависимости точности модели от уровня сжатия в 0, 2 и 4 раза.\n",
        "\n",
        "В виде решения нужно будет сдать ноутбук с построенными графиками и выводами, в частности ответить на вопрос какой метод компрессии выбрать для сохранения наилучшего качества.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV3IRNDy28hR"
      },
      "source": [
        "## Подготовка окружения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Okd5YfuDPhXh"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade datasets accelerate lm-eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sSeSzWMyFH1k"
      },
      "outputs": [],
      "source": [
        "!mkdir spars_quant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3PFbThAFH1k",
        "outputId": "0490c444-1be6-43b5-8aa2-dd50da823aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/spars_quant\n"
          ]
        }
      ],
      "source": [
        "%cd ./spars_quant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWrXNxq-FH1l",
        "outputId": "ed2f6c5e-d6a8-4180-f5e4-01df10ac8d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/spars_quant/.git/\n",
            "Updating origin\n",
            "remote: Enumerating objects: 498, done.\u001b[K\n",
            "remote: Counting objects: 100% (188/188), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 498 (delta 51), reused 167 (delta 44), pack-reused 310 (from 1)\u001b[K\n",
            "Receiving objects: 100% (498/498), 518.78 MiB | 21.54 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n",
            "From https://github.com/On-Point-RND/Efficient-DL-models-Seminars\n",
            " * [new branch]      master     -> origin/master\n",
            "From https://github.com/On-Point-RND/Efficient-DL-models-Seminars\n",
            " * branch            master     -> FETCH_HEAD\n"
          ]
        }
      ],
      "source": [
        "!git init\n",
        "!git remote add -f origin https://github.com/On-Point-RND/Efficient-DL-models-Seminars.git\n",
        "!git config core.sparseCheckout true\n",
        "!echo \"Home Work/HW 1\" >> .git/info/sparse-checkout\n",
        "!git pull origin master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmjacKaGFH1l",
        "outputId": "dc0502b6-21d8-41f4-e2c2-3bf927e6468f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vzTkTQvR3QTn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "SAVING_DIR = '/content/'\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = SAVING_DIR + \"hf_cache/\"\n",
        "os.environ[\"HF_HOME\"] = SAVING_DIR + \"hf_cache/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3izCW0_CjeV"
      },
      "source": [
        "## Загрузка модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6QqJ0l8Cm9l"
      },
      "source": [
        "https://huggingface.co/facebook/opt-350m <br>\n",
        "\n",
        "OPT: Open Pre-trained Transformer Language Models <br>\n",
        "Семейство моделей с архитектурой GPT-трансформера, выпущенные в начале 2022 года. Обучение моделей выполнялось на корпусах, состоящих преимущественно из текстов на английском языке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "966rnVeL51bR",
        "outputId": "77fa5989-f069-46af-f9d3-f3c0afeeb974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'opt-350m'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 115 (delta 59), reused 115 (delta 59), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (115/115), 558.76 KiB | 4.23 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n",
            "Filtering content: 100% (3/3), 1.85 GiB | 59.38 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/facebook/opt-350m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3dL56NJH6cy"
      },
      "source": [
        "## lm-evaluation-harness <br>\n",
        "\n",
        "https://github.com/EleutherAI/lm-evaluation-harness/ <br>\n",
        "\n",
        "harness - единый фреймворк для тестирования эффективности языковых модели на большом количестве различных заданий. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq7H9U8lTE2G"
      },
      "source": [
        "https://huggingface.co/datasets/winogrande <br>\n",
        "\n",
        "WinoGrande - коллекция из 44 тыс. вопросов, вдохновленная Winograd Schema Challenge (Левеск, Дэвис и Моргенштерн, 2011). Каждый вопрос формулируется в виде тестового задания с двумя ответами. Цель выбрать правильный ответ, что требует рассуждений на основе здравого смысла."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3uDU9hZTOJd"
      },
      "source": [
        "<img src=\"https://github.com/iptkachev/Efficient-DL-Models/blob/master/Home%20Work/HW%201/notebooks/images/winogrande.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgaASPLmTygf"
      },
      "source": [
        "https://huggingface.co/datasets/google/boolq\n",
        "\n",
        "BoolQ - набор из 15942 заданий с ответами \"да\"/\"нет\" на вопросы, которые формулируются на основе отрывка текста."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYH5OTlHTZdN"
      },
      "source": [
        "<img  src=\"https://github.com/iptkachev/Efficient-DL-Models/blob/master/Home%20Work/HW%201/notebooks/images/boolq.png?raw=1\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItamzBY8HVf3",
        "outputId": "3573c361-3bca-4e69-c389-fa097efd2938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-12-01 16:53:00.539492: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 16:53:00.558700: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 16:53:00.564529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 16:53:00.578302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 16:53:01.698494: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-12-01:16:53:03,541 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-12-01:16:53:13,823 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:16:53:13,850 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:16:53:14,134 INFO     [__main__.py:376] Selected Tasks: ['boolq', 'winogrande']\n",
            "2024-12-01:16:53:14,136 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
            "2024-12-01:16:53:14,136 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': '/content/opt-350m'}\n",
            "2024-12-01:16:53:14,193 INFO     [huggingface.py:129] Using device 'cuda'\n",
            "2024-12-01:16:53:14,195 INFO     [huggingface.py:481] Using model type 'default'\n",
            "2024-12-01:16:53:14,333 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
            "2024-12-01:16:53:15,239 WARNING  [task.py:799] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-12-01:16:53:15,239 WARNING  [task.py:811] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "README.md: 100% 18.2k/18.2k [00:00<00:00, 82.8MB/s]\n",
            "super_glue.py: 100% 30.7k/30.7k [00:00<00:00, 93.6MB/s]\n",
            "README.md: 100% 9.97k/9.97k [00:00<00:00, 47.7MB/s]\n",
            "winogrande.py: 100% 5.65k/5.65k [00:00<00:00, 29.6MB/s]\n",
            "Downloading data: 100% 3.40M/3.40M [00:00<00:00, 138MB/s]\n",
            "Generating train split: 100% 40398/40398 [00:02<00:00, 14526.55 examples/s]\n",
            "Generating test split: 100% 1767/1767 [00:00<00:00, 24322.27 examples/s]\n",
            "Generating validation split: 100% 1267/1267 [00:00<00:00, 25888.12 examples/s]\n",
            "2024-12-01:16:53:22,919 WARNING  [evaluator.py:270] Overwriting default num_fewshot of winogrande from None to 0\n",
            "2024-12-01:16:53:22,919 WARNING  [evaluator.py:270] Overwriting default num_fewshot of boolq from None to 0\n",
            "2024-12-01:16:53:22,919 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-12-01:16:53:22,920 INFO     [task.py:415] Building contexts for winogrande on rank 0...\n",
            "100% 1267/1267 [00:00<00:00, 85343.73it/s]\n",
            "2024-12-01:16:53:22,976 INFO     [task.py:415] Building contexts for boolq on rank 0...\n",
            "100% 3270/3270 [00:01<00:00, 1867.05it/s]\n",
            "2024-12-01:16:53:24,845 INFO     [evaluator.py:489] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 9074/9074 [00:31<00:00, 286.29it/s]\n",
            "2024-12-01:16:54:02,837 WARNING  [huggingface.py:1353] Failed to get model SHA for /content/opt-350m at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/opt-350m'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2024-12-01:16:54:04,847 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated\n",
            "hf (pretrained=/content/opt-350m), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
            "|boolq     |      2|none  |     0|acc   |↑  |0.5771|±  |0.0086|\n",
            "|winogrande|      1|none  |     0|acc   |↑  |0.5225|±  |0.0140|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "--model_args \"pretrained=/content/opt-350m\" \\\n",
        "--tasks winogrande,boolq \\\n",
        "--batch_size 4 \\\n",
        "--num_fewshot 0 \\\n",
        "--device cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w07cmytIFESp"
      },
      "source": [
        "## Метод квантизации QUIK <br>\n",
        "\n",
        "https://github.com/IST-DASLab/QUIK/tree/master <br>\n",
        "https://arxiv.org/pdf/2310.09259.pdf <br>\n",
        "\n",
        "<img src=\"https://github.com/iptkachev/Efficient-DL-Models/blob/master/Home%20Work/HW%201/notebooks/images/quik.png?raw=1\">\n",
        "\n",
        "Метод GPTQ выполняет послойную квантизацию модели с компенсацией ошибки квантизации путем обновления еще не квантизованных весов. <br>\n",
        "Для каждого линейного слоя матрица весов $\\mathbf{W}$ квантизуется последовательно по столбцам, при этом еще не квантизованные веса обновляются, чтобы компенсировать возникшую ошибку:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\mathbf{W}_{update} = \\mathbf{W} + \\delta \\mathbf{W} = \\mathbf{W} + \\dfrac{(\\tilde{\\mathbf{W}}_{m} - \\mathbf{W}_{m})}{[\\mathbf{H}^{-1}]_{mm}} \\mathbf{H}^{-1}_{:, m}, \\quad \\mathbf{H} = \\mathbf{X}\\mathbf{X}^{T}\n",
        "\\end{equation}$\n",
        "\n",
        "где $m$ - индекс столбца, который квантизуется, $\\mathbf{X}$ - матрица активаций, $\\tilde{\\mathbf{W}}$ - деквантизованные веса. <br>\n",
        "Для того чтобы ускорить процесс квантизации и не обновлять всю матрицу $\\mathbf{W}$ после квантизации каждого столбца, они объединяются в блоки (стандартный размер 128). При таком подходе, неквантизованные веса обновляются только в рамках одного блока.\n",
        "\n",
        "Метод QUIK - улучшение версия метода GPTQ, в котором в матрицах весов $W$ каждого слоя модели выделяются столбцы outliers. Данные столбцы не квантизуются, что дает возможность существенно повысить качество модели\n",
        "без значительного увеличения в ее размере. В отличии от LLM.int8() столбцы outliers определяются заранее, исходя из максимального значения активаций в каждом слое, расчитанных на калибровочном датасете. Благодаря этому метод QUIK имеет более высокую скорость инференса по сравнению с LLM.int8().\n",
        "\n",
        "\n",
        "Выбор чувствительных к квантизации столбцов в QUIK выбирается, исходя значения активаций $\\mathbf{X}$, посчитанных на калибровочном датасете:\n",
        "\n",
        "$\n",
        "\\mathbf{i} =  \\underset{\\mathbf{i}}{argmax}\\mathbf{X}, \\\\ $\n",
        "где $\\mathbf{i}$ - 128 индексов столбцов, которые не квантизуются и остаются в fp16.\n",
        "\n",
        "Более подробно про методы квантизации GPTQ и LLM.int8() будет рассказано в лекции про оптимизацию LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EYHZpNkJkZF"
      },
      "source": [
        "<em> Описание параметров: </em>\n",
        "\n",
        "`model` - путь к директории, где хранится модель. <br>\n",
        "`path_to_act_scales` - путь к файлу с максимальными значений активаций для каждого слоя. <br>\n",
        "Данный файл может быть получен с помощью `generate_act_scales.py` из репозитория `https://github.com/mit-han-lab/smoothquant/tree/main`. <br>\n",
        "`path_to_save_quant_model` - путь к директории, где будет сохранена модель после квантизации. Модель сохранятся с деквантизованными fp весами. <br>\n",
        "`fp_features` - количество столбцов outliers в каждом слое, которые не будут квантизованы. <br>\n",
        "`a_bits` - уровень битности [4, 8, 16], в котором будут вычислены активации для каждого слоя. Если уровень битности меньше 16, то активации квантизуются. Но активации, соответствующие столбцам outliers, остаются всегда в fp16/bf16. <br>\n",
        "`w_bits` - уровень квантизации [4, 8, 16] весов модели. сли уровень битности 16, то веса не квантизуются. <br>\n",
        "`w_clip` - индикатор, указывающий, что коэффициент $\\alpha$, который используется для масштабирования весов модели $\\dfrac{\\mathrm{abs}(\\mathbf{W})}{\\alpha}$ при квантизации, будет найден путем подбора, исходя из минимизации ошибки квантизации $ \\lVert \\mathbf{W} - \\tilde{\\mathbf{W}} \\rVert_{2}$, где $\\tilde{\\mathbf{W}}$ - деквантизованные веса. Поскольку в этом случае значение $\\alpha$ может быть меньше, чем максимальное значение весов $\\mathbf{W}$, то веса модели после квантизации $(2^{\\mathrm{w\\_bits} - 1} - 1)\\dfrac{\\mathbf{W}}{\\alpha}$ ограничиваются до промежутка $[-2^{\\mathrm{w\\_bits} - 1},\\, 2^{\\mathrm{w\\_bits} - 1} - 1]$. <br>\n",
        "`dataset` - калиброчовный датасет, который используется для вычисления матрицы Гессе $\\mathbf{H}$ для каждого слоя модели.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTJKiwp0557K",
        "outputId": "e4ceadd2-f5a6-4675-f34b-ad5122cb75e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-12-01 17:05:52.661476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 17:05:52.681486: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 17:05:52.687623: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 17:05:52.702100: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 17:05:53.877159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(model='/content/opt-350m', path_to_save_quant_model='/content/weight/opt_350_w4_a16', path_to_act_scales='/content/spars_quant/Home Work/HW 1/quik/experiments/act_scales/opt_350m.pt', dataset='wikitext2', seed=0, nsamples=128, percdamp=0.01, fp_features=128, a_bits=16, w_bits=4, w_clip=True, w_asym=False, sparsity=0, prunen=0, prunem=0, wandb=False, wandb_name='anonymous', int8_2_4=False, smoothquant=False, synthetic_data=False, sparseGPT=False)\n",
            "Loading /content/opt-350m Model...\n",
            "/content/spars_quant/Home Work/HW 1/quik/experiments/fake_quant/opt.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  act_scales = torch.load(path_to_act_scales)\n",
            "Loaded act_scales from:  /content/spars_quant/Home Work/HW 1/quik/experiments/act_scales/opt_350m.pt\n",
            "README.md: 100% 10.5k/10.5k [00:00<00:00, 48.3MB/s]\n",
            "test-00000-of-00001.parquet: 100% 733k/733k [00:00<00:00, 17.9MB/s]\n",
            "train-00000-of-00001.parquet: 100% 6.36M/6.36M [00:00<00:00, 115MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 657k/657k [00:00<00:00, 148MB/s]\n",
            "Generating test split: 100% 4358/4358 [00:00<00:00, 163734.04 examples/s]\n",
            "Generating train split: 100% 36718/36718 [00:00<00:00, 673950.52 examples/s]\n",
            "Generating validation split: 100% 3760/3760 [00:00<00:00, 584355.38 examples/s]\n",
            "Starting ...\n",
            "Ready.\n",
            "\n",
            "Layer: 0: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 1: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 2: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 3: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 4: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 5: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 6: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 7: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 8: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 9: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 10: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 11: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 12: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 13: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 14: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 15: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 16: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 17: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 18: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 19: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 20: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 21: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 22: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 \n",
            "Layer: 23: self_attn.k_proj  self_attn.v_proj  self_attn.q_proj  self_attn.out_proj  fc1  fc2 wikitext2\n",
            "Layers: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23\n",
            "WIKITEXT2 PPL: 22.398\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python /content/spars_quant/Home\\ Work/HW\\ 1/quik/experiments/fake_quant/opt.py \\\n",
        "    --model /content/opt-350m \\\n",
        "    --path_to_act_scales /content/spars_quant/Home\\ Work/HW\\ 1/quik/experiments/act_scales/opt_350m.pt \\\n",
        "    --path_to_save_quant_model /content/weight/opt_350_w4_a16 \\\n",
        "    --fp_features 128 \\\n",
        "    --a_bits 16 \\\n",
        "    --w_bits 4 \\\n",
        "    --w_clip \\\n",
        "    --dataset wikitext2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mbx8j0B552r",
        "outputId": "247ee91f-dfeb-4337-df22-20344116b727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-12-01 17:15:42.850868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 17:15:42.870401: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 17:15:42.876271: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 17:15:42.890628: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 17:15:44.075468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-12-01:17:15:46,621 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-12-01:17:15:55,890 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:17:15:55,918 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:17:15:56,204 INFO     [__main__.py:376] Selected Tasks: ['boolq', 'winogrande']\n",
            "2024-12-01:17:15:56,207 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
            "2024-12-01:17:15:56,207 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': '/content/weight/opt_350_w4_a16'}\n",
            "2024-12-01:17:15:56,286 INFO     [huggingface.py:129] Using device 'cuda'\n",
            "2024-12-01:17:15:56,288 INFO     [huggingface.py:481] Using model type 'default'\n",
            "2024-12-01:17:15:56,430 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
            "2024-12-01:17:15:57,211 WARNING  [task.py:799] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-12-01:17:15:57,211 WARNING  [task.py:811] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "2024-12-01:17:16:01,447 WARNING  [evaluator.py:270] Overwriting default num_fewshot of winogrande from None to 0\n",
            "2024-12-01:17:16:01,447 WARNING  [evaluator.py:270] Overwriting default num_fewshot of boolq from None to 0\n",
            "2024-12-01:17:16:01,447 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-12-01:17:16:01,449 INFO     [task.py:415] Building contexts for winogrande on rank 0...\n",
            "100% 1267/1267 [00:00<00:00, 85508.51it/s]\n",
            "2024-12-01:17:16:01,505 INFO     [task.py:415] Building contexts for boolq on rank 0...\n",
            "100% 3270/3270 [00:01<00:00, 1855.80it/s]\n",
            "2024-12-01:17:16:03,379 INFO     [evaluator.py:489] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 9074/9074 [02:48<00:00, 53.70it/s]\n",
            "2024-12-01:17:18:58,686 WARNING  [huggingface.py:1353] Failed to get model SHA for /content/weight/opt_350_w4_a16 at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/weight/opt_350_w4_a16'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2024-12-01:17:18:59,902 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated\n",
            "hf (pretrained=/content/weight/opt_350_w4_a16), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
            "|boolq     |      2|none  |     0|acc   |↑  |0.5651|±  |0.0087|\n",
            "|winogrande|      1|none  |     0|acc   |↑  |0.5296|±  |0.0140|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args \"pretrained=/content/weight/opt_350_w4_a16\" \\\n",
        "    --tasks winogrande,boolq \\\n",
        "    --batch_size 4 \\\n",
        "    --num_fewshot 0 \\\n",
        "    --device cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i-RnVaLaO6R"
      },
      "source": [
        "## Метод спарсификации SparseGPT\n",
        "\n",
        "https://github.com/IST-DASLab/sparsegpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcIdikzNcT7-"
      },
      "source": [
        "SparseGPT - метод спарсификации LLM, основанные на процедуре Optimal Brain Surgeon (OBS). Оценка значимости каждого веса $w_{m}$ в матрице весов $\\mathbf{W}$ выполняется, исходя из его влияния на функцию Лагранжа:\n",
        "\n",
        "\\begin{equation}\n",
        "L = \\dfrac{1}{2} \\dfrac{w_{m}^{2}}{[\\mathbf{H}^{-1}]_{mm}}.\n",
        "\\end{equation}\n",
        "\n",
        "Согласно теории OBS функция Лагранжа $L$ связана с ошибкой $E$, вызванной занулением веса $w_{m}$:\n",
        "\n",
        "$\\begin{equation}\n",
        "E = \\lVert \\mathbf{W}\\mathbf{X} - \\tilde{\\mathbf{W}}\\mathbf{X} \\rVert_{2}^{2},\n",
        "\\end{equation}$\n",
        "где $\\tilde{\\mathbf{W}}$ - матрица весов после зануления $w_{m}$.\n",
        "\n",
        "После расчета значимости каждого веса в выбранном слое, выполняется последовательное (слево-направо) обнуления малозначимых весов $w_{m}$. По аналогии с GPTQ обнуление весов выполняется по столбцам, которые сгруппированы в блоки.\n",
        "При этом ошибка, вызыванная спарсификацией, компенсируется путем калибровки весов, находящихся в одной строке с зануленными весами $\\mathbf{w}_{m}$:\n",
        "\n",
        "$\\begin{align}\n",
        "\\mathbf{w}_{update} = \\mathbf{w} + \\delta \\mathbf{w} = \\mathbf{w} + \\dfrac{\\mathbf{w}_{m}}{[\\mathbf{H}^{-1}]_{mm}} \\mathbf{H}^{-1}_{:, m}\n",
        "\\end{align}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay17rV6jFH1m"
      },
      "source": [
        "<em> Описание параметров </em>\n",
        "`model` - путь к директории, где хранится модель. <br>\n",
        "`dataset` - калибровочный датасет, который используется для расчета матрицы Гессе $\\mathbf{H}$. <br>\n",
        "`sparsity` - коэффициент спарсификации, в интервале от 0.0 (оригинальная модель) до 1.0.<br>\n",
        "`wbits` - уровень битности для спарсифированной модели [4, 8, 16]. Если уровень битности меньше 16, то\n",
        "вместе со спарсификацией будет выполнена также квантизация модели методом GPTQ. Если уровень спрасификации 0.0, то будет выполнена только квантизация методом GPTQ. <br>\n",
        "`sparsity_type` - тип спарсификации. <br>\n",
        "`save_model` - путь к директории, в которой будет сохранена модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWr_9rNOFH1m",
        "outputId": "85648aa7-9c10-48ed-9788-2246988e1802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-12-01 17:19:08.956299: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 17:19:08.976518: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 17:19:08.982499: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 17:19:08.998011: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 17:19:10.209483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Starting ...\n",
            "Ready.\n",
            "0 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.28\n",
            "error 916.826904296875\n",
            "0 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 22.81218719482422\n",
            "0 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.26\n",
            "error 464.78192138671875\n",
            "0 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 0.030126027762889862\n",
            "0 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 154873.21875\n",
            "0 fc2\n",
            "Pruning ...\n",
            "time 1.05\n",
            "error 1772.52734375\n",
            "1 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.02\n",
            "error 37470.421875\n",
            "1 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 17364.23046875\n",
            "1 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 41320.1640625\n",
            "1 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 504.6702880859375\n",
            "1 fc1\n",
            "Pruning ...\n",
            "time 0.26\n",
            "error 169577.1875\n",
            "1 fc2\n",
            "Pruning ...\n",
            "time 1.01\n",
            "error 1754.7218017578125\n",
            "2 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.04\n",
            "error 56818.7421875\n",
            "2 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 25166.404296875\n",
            "2 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 59228.87890625\n",
            "2 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 610.5534057617188\n",
            "2 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 179603.375\n",
            "2 fc2\n",
            "Pruning ...\n",
            "time 1.01\n",
            "error 2022.55029296875\n",
            "3 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.06\n",
            "error 62411.015625\n",
            "3 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 31408.384765625\n",
            "3 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 64971.1953125\n",
            "3 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 568.72412109375\n",
            "3 fc1\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 183149.625\n",
            "3 fc2\n",
            "Pruning ...\n",
            "time 1.03\n",
            "error 2276.967529296875\n",
            "4 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.06\n",
            "error 64911.11328125\n",
            "4 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 29519.7890625\n",
            "4 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 68309.46875\n",
            "4 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 655.888671875\n",
            "4 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 185354.078125\n",
            "4 fc2\n",
            "Pruning ...\n",
            "time 1.00\n",
            "error 2479.21337890625\n",
            "5 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.05\n",
            "error 45075.6171875\n",
            "5 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 28405.71484375\n",
            "5 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 48243.74609375\n",
            "5 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 466.36114501953125\n",
            "5 fc1\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 191037.09375\n",
            "5 fc2\n",
            "Pruning ...\n",
            "time 1.00\n",
            "error 2561.993408203125\n",
            "6 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.04\n",
            "error 45419.546875\n",
            "6 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 24462.3125\n",
            "6 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 52907.7578125\n",
            "6 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 803.67333984375\n",
            "6 fc1\n",
            "Pruning ...\n",
            "time 0.32\n",
            "error 201962.53125\n",
            "6 fc2\n",
            "Pruning ...\n",
            "time 1.36\n",
            "error 2810.48681640625\n",
            "7 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.11\n",
            "error 54031.16796875\n",
            "7 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.34\n",
            "error 27750.5703125\n",
            "7 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 62135.1328125\n",
            "7 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 1262.930419921875\n",
            "7 fc1\n",
            "Pruning ...\n",
            "time 0.36\n",
            "error 218916.90625\n",
            "7 fc2\n",
            "Pruning ...\n",
            "time 1.07\n",
            "error 3388.7265625\n",
            "8 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.07\n",
            "error 67844.5859375\n",
            "8 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 29779.03125\n",
            "8 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 78052.96875\n",
            "8 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 1847.349609375\n",
            "8 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 216189.6875\n",
            "8 fc2\n",
            "Pruning ...\n",
            "time 1.00\n",
            "error 4540.69287109375\n",
            "9 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.05\n",
            "error 77656.84375\n",
            "9 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 32641.1640625\n",
            "9 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 89851.9296875\n",
            "9 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 2086.79150390625\n",
            "9 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 213590.875\n",
            "9 fc2\n",
            "Pruning ...\n",
            "time 1.00\n",
            "error 4572.2744140625\n",
            "10 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.08\n",
            "error 79990.890625\n",
            "10 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 40423.3984375\n",
            "10 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 85190.0\n",
            "10 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 3202.074951171875\n",
            "10 fc1\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 232483.96875\n",
            "10 fc2\n",
            "Pruning ...\n",
            "time 0.99\n",
            "error 4925.4384765625\n",
            "11 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.05\n",
            "error 73247.109375\n",
            "11 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 48528.359375\n",
            "11 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 79040.796875\n",
            "11 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 2326.939697265625\n",
            "11 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 235368.96875\n",
            "11 fc2\n",
            "Pruning ...\n",
            "time 1.00\n",
            "error 5640.94873046875\n",
            "12 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.06\n",
            "error 78740.1484375\n",
            "12 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 58442.6171875\n",
            "12 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.26\n",
            "error 83499.6796875\n",
            "12 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 3655.94970703125\n",
            "12 fc1\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 252152.796875\n",
            "12 fc2\n",
            "Pruning ...\n",
            "time 1.03\n",
            "error 5512.12841796875\n",
            "13 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.05\n",
            "error 78395.0078125\n",
            "13 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 57779.609375\n",
            "13 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 83745.0\n",
            "13 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 3904.19482421875\n",
            "13 fc1\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 251364.625\n",
            "13 fc2\n",
            "Pruning ...\n",
            "time 0.99\n",
            "error 6130.390625\n",
            "14 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.06\n",
            "error 87193.4453125\n",
            "14 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 64775.36328125\n",
            "14 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 92553.0625\n",
            "14 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 2282.562744140625\n",
            "14 fc1\n",
            "Pruning ...\n",
            "time 0.26\n",
            "error 246846.15625\n",
            "14 fc2\n",
            "Pruning ...\n",
            "time 1.33\n",
            "error 5668.763671875\n",
            "15 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.16\n",
            "error 86584.75\n",
            "15 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.33\n",
            "error 59240.5390625\n",
            "15 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.33\n",
            "error 91720.203125\n",
            "15 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.36\n",
            "error 1847.82958984375\n",
            "15 fc1\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 240849.4375\n",
            "15 fc2\n",
            "Pruning ...\n",
            "time 1.28\n",
            "error 5419.00537109375\n",
            "16 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.16\n",
            "error 88481.0625\n",
            "16 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 63830.92578125\n",
            "16 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 92861.46875\n",
            "16 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 2291.444580078125\n",
            "16 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 231267.125\n",
            "16 fc2\n",
            "Pruning ...\n",
            "time 1.00\n",
            "error 5206.40771484375\n",
            "17 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.04\n",
            "error 83692.546875\n",
            "17 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 60004.2578125\n",
            "17 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.26\n",
            "error 88272.5625\n",
            "17 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 1830.1929931640625\n",
            "17 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 219142.359375\n",
            "17 fc2\n",
            "Pruning ...\n",
            "time 1.02\n",
            "error 4904.19189453125\n",
            "18 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.04\n",
            "error 77541.078125\n",
            "18 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 58868.296875\n",
            "18 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 82612.328125\n",
            "18 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 1854.4691162109375\n",
            "18 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 203594.1875\n",
            "18 fc2\n",
            "Pruning ...\n",
            "time 0.99\n",
            "error 4436.5595703125\n",
            "19 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.04\n",
            "error 74164.09375\n",
            "19 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.23\n",
            "error 46244.828125\n",
            "19 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 78226.9375\n",
            "19 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 2300.011474609375\n",
            "19 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 191385.296875\n",
            "19 fc2\n",
            "Pruning ...\n",
            "time 1.01\n",
            "error 3786.080810546875\n",
            "20 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.04\n",
            "error 59192.015625\n",
            "20 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 40609.640625\n",
            "20 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 70562.6875\n",
            "20 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 3220.5654296875\n",
            "20 fc1\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 198413.703125\n",
            "20 fc2\n",
            "Pruning ...\n",
            "time 1.01\n",
            "error 3886.52783203125\n",
            "21 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.05\n",
            "error 60640.359375\n",
            "21 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 41455.72265625\n",
            "21 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 79229.0078125\n",
            "21 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 3510.27685546875\n",
            "21 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 201631.3125\n",
            "21 fc2\n",
            "Pruning ...\n",
            "time 1.01\n",
            "error 4232.8466796875\n",
            "22 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.06\n",
            "error 65516.8046875\n",
            "22 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.25\n",
            "error 44954.203125\n",
            "22 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 104601.0859375\n",
            "22 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 5696.34375\n",
            "22 fc1\n",
            "Pruning ...\n",
            "time 0.24\n",
            "error 189421.71875\n",
            "22 fc2\n",
            "Pruning ...\n",
            "time 1.14\n",
            "error 5350.54248046875\n",
            "23 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 1.07\n",
            "error 72601.03125\n",
            "23 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.36\n",
            "error 63787.765625\n",
            "23 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.33\n",
            "error 84690.421875\n",
            "23 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.32\n",
            "error 6995.55029296875\n",
            "23 fc1\n",
            "Pruning ...\n",
            "time 0.31\n",
            "error 152331.25\n",
            "23 fc2\n",
            "Pruning ...\n",
            "time 1.53\n",
            "error 3288.32958984375\n",
            "model.decoder.embed_tokens.weight tensor(5.8277e-07)\n",
            "model.decoder.embed_positions.weight tensor(0.0005)\n",
            "model.decoder.project_out.weight tensor(0.)\n",
            "model.decoder.project_in.weight tensor(0.)\n",
            "model.decoder.layers.0.self_attn.k_proj.weight tensor(0.5000)\n",
            "model.decoder.layers.0.self_attn.k_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.v_proj.weight tensor(0.5000)\n",
            "model.decoder.layers.0.self_attn.v_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.q_proj.weight tensor(0.5000)\n",
            "model.decoder.layers.0.self_attn.q_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.out_proj.weight tensor(0.5000)\n",
            "model.decoder.layers.0.self_attn.out_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight tensor(0.)\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias tensor(0.)\n",
            "model.decoder.layers.0.fc1.weight tensor(0.5000)\n",
            "model.decoder.layers.0.fc1.bias tensor(0.)\n",
            "model.decoder.layers.0.fc2.weight tensor(0.5000)\n",
            "352.043408870697\n",
            "wikitext2\n",
            "Evaluating ...\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "Perplexity: 29.025999\n"
          ]
        }
      ],
      "source": [
        "!python  /content/spars_quant/Home\\ Work/HW\\ 1/sparsegpt/opt.py \\\n",
        "    --model /content/opt-350m \\\n",
        "    --dataset wikitext2 \\\n",
        "    --sparsity 0.5 \\\n",
        "    --wbits 16 \\\n",
        "    --save /content/weights/opt350m_sparsegpt_50_w16_a16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0hB2ysEFH1m",
        "outputId": "75f71afd-5ab4-4fbf-ec12-adc3de4f4505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-12-01 17:29:20.638180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 17:29:20.658929: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 17:29:20.664904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 17:29:20.678950: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 17:29:21.867649: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-12-01:17:29:23,728 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-12-01:17:29:34,168 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:17:29:34,196 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:17:29:34,482 INFO     [__main__.py:376] Selected Tasks: ['boolq', 'winogrande']\n",
            "2024-12-01:17:29:34,484 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
            "2024-12-01:17:29:34,484 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': '/content/weights/opt350m_sparsegpt_50_w16_a16'}\n",
            "2024-12-01:17:29:34,543 INFO     [huggingface.py:129] Using device 'cuda'\n",
            "2024-12-01:17:29:34,545 INFO     [huggingface.py:481] Using model type 'default'\n",
            "2024-12-01:17:29:34,675 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
            "2024-12-01:17:29:35,455 WARNING  [task.py:799] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-12-01:17:29:35,455 WARNING  [task.py:811] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "2024-12-01:17:29:39,121 WARNING  [evaluator.py:270] Overwriting default num_fewshot of winogrande from None to 0\n",
            "2024-12-01:17:29:39,121 WARNING  [evaluator.py:270] Overwriting default num_fewshot of boolq from None to 0\n",
            "2024-12-01:17:29:39,121 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-12-01:17:29:39,123 INFO     [task.py:415] Building contexts for winogrande on rank 0...\n",
            "100% 1267/1267 [00:00<00:00, 83731.44it/s]\n",
            "2024-12-01:17:29:39,178 INFO     [task.py:415] Building contexts for boolq on rank 0...\n",
            "100% 3270/3270 [00:01<00:00, 1869.93it/s]\n",
            "2024-12-01:17:29:41,039 INFO     [evaluator.py:489] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 9074/9074 [02:47<00:00, 54.12it/s]\n",
            "2024-12-01:17:32:36,614 WARNING  [huggingface.py:1353] Failed to get model SHA for /content/weights/opt350m_sparsegpt_50_w16_a16 at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/weights/opt350m_sparsegpt_50_w16_a16'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2024-12-01:17:32:37,873 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated\n",
            "hf (pretrained=/content/weights/opt350m_sparsegpt_50_w16_a16), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
            "|boolq     |      2|none  |     0|acc   |↑  |0.5933|±  |0.0086|\n",
            "|winogrande|      1|none  |     0|acc   |↑  |0.5122|±  |0.0140|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args \"pretrained=/content/weights/opt350m_sparsegpt_50_w16_a16\" \\\n",
        "    --tasks winogrande,boolq \\\n",
        "    --batch_size 4 \\\n",
        "    --num_fewshot 0 \\\n",
        "    --device cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocMobNlhFH1m"
      },
      "source": [
        "Пример запуска скрипта для квантизации модели методом GPTQ до уровня 4 бит (wbits = 4). <br>\n",
        "Для того чтобы одновременно выполнить квантизацию и спарсификацию, необходимо указать коэффициент\n",
        "спарсификации (напр. sparsity = 50%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAW8m2d5FH1m",
        "outputId": "64e96e51-f389-4ed2-f01a-193098bf9e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-12-01 17:33:03.558493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 17:33:03.577624: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 17:33:03.583562: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 17:33:03.597528: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 17:33:04.787472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Starting ...\n",
            "Ready.\n",
            "0 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.87\n",
            "error 43.998023986816406\n",
            "0 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.54\n",
            "error 4.006092548370361\n",
            "0 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 62.47447204589844\n",
            "0 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 0.01482384279370308\n",
            "0 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 20926.126953125\n",
            "0 fc2\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 431.722412109375\n",
            "1 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 6493.546875\n",
            "1 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 3202.25390625\n",
            "1 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 5889.23583984375\n",
            "1 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 137.31930541992188\n",
            "1 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 25999.63671875\n",
            "1 fc2\n",
            "Pruning ...\n",
            "time 1.55\n",
            "error 464.8421325683594\n",
            "2 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 8656.521484375\n",
            "2 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 4580.03466796875\n",
            "2 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 8692.93359375\n",
            "2 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 138.04061889648438\n",
            "2 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 29855.49609375\n",
            "2 fc2\n",
            "Pruning ...\n",
            "time 1.60\n",
            "error 636.14599609375\n",
            "3 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 9809.5546875\n",
            "3 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 5603.93994140625\n",
            "3 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 10230.048828125\n",
            "3 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 110.60444641113281\n",
            "3 fc1\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 32388.962890625\n",
            "3 fc2\n",
            "Pruning ...\n",
            "time 1.89\n",
            "error 775.4251708984375\n",
            "4 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.54\n",
            "error 10519.05859375\n",
            "4 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.57\n",
            "error 5579.9794921875\n",
            "4 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.57\n",
            "error 10826.0693359375\n",
            "4 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.60\n",
            "error 145.60073852539062\n",
            "4 fc1\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 34184.578125\n",
            "4 fc2\n",
            "Pruning ...\n",
            "time 1.65\n",
            "error 855.731201171875\n",
            "5 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 8987.818359375\n",
            "5 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 5493.6513671875\n",
            "5 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 9483.6201171875\n",
            "5 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 141.38626098632812\n",
            "5 fc1\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 35737.8125\n",
            "5 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 934.0386352539062\n",
            "6 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 11221.3037109375\n",
            "6 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 5103.28662109375\n",
            "6 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 10493.0517578125\n",
            "6 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 266.38677978515625\n",
            "6 fc1\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 38184.95703125\n",
            "6 fc2\n",
            "Pruning ...\n",
            "time 1.60\n",
            "error 1132.369384765625\n",
            "7 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 12701.703125\n",
            "7 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 5803.87890625\n",
            "7 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 11613.951171875\n",
            "7 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 405.8078918457031\n",
            "7 fc1\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 41869.01953125\n",
            "7 fc2\n",
            "Pruning ...\n",
            "time 1.62\n",
            "error 1489.699951171875\n",
            "8 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 15407.6845703125\n",
            "8 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 6482.1689453125\n",
            "8 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 14125.4580078125\n",
            "8 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.54\n",
            "error 562.2284545898438\n",
            "8 fc1\n",
            "Pruning ...\n",
            "time 0.47\n",
            "error 43342.546875\n",
            "8 fc2\n",
            "Pruning ...\n",
            "time 2.21\n",
            "error 2071.16259765625\n",
            "9 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.54\n",
            "error 15199.673828125\n",
            "9 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 6831.84619140625\n",
            "9 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 14675.4267578125\n",
            "9 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 634.8521118164062\n",
            "9 fc1\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 43547.4921875\n",
            "9 fc2\n",
            "Pruning ...\n",
            "time 1.56\n",
            "error 2098.835693359375\n",
            "10 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 15682.830078125\n",
            "10 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 8124.24072265625\n",
            "10 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 15684.6552734375\n",
            "10 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 789.950439453125\n",
            "10 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 47598.859375\n",
            "10 fc2\n",
            "Pruning ...\n",
            "time 1.59\n",
            "error 2217.88330078125\n",
            "11 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 15597.021484375\n",
            "11 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 9381.732421875\n",
            "11 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 14982.998046875\n",
            "11 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 602.8322143554688\n",
            "11 fc1\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 48884.84375\n",
            "11 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 2505.85791015625\n",
            "12 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 16050.408203125\n",
            "12 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 11278.037109375\n",
            "12 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 16438.51171875\n",
            "12 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 913.701171875\n",
            "12 fc1\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 52036.01953125\n",
            "12 fc2\n",
            "Pruning ...\n",
            "time 2.58\n",
            "error 2351.8271484375\n",
            "13 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.56\n",
            "error 16892.68359375\n",
            "13 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.57\n",
            "error 11323.85546875\n",
            "13 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.54\n",
            "error 16205.830078125\n",
            "13 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 892.1993408203125\n",
            "13 fc1\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 52443.4921875\n",
            "13 fc2\n",
            "Pruning ...\n",
            "time 1.68\n",
            "error 2489.74951171875\n",
            "14 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 16871.2109375\n",
            "14 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 12081.248046875\n",
            "14 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 17005.509765625\n",
            "14 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 517.8112182617188\n",
            "14 fc1\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 52766.76171875\n",
            "14 fc2\n",
            "Pruning ...\n",
            "time 1.58\n",
            "error 2307.36181640625\n",
            "15 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 17090.1484375\n",
            "15 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 11484.48828125\n",
            "15 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 17053.9921875\n",
            "15 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 494.21466064453125\n",
            "15 fc1\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 51966.7578125\n",
            "15 fc2\n",
            "Pruning ...\n",
            "time 1.57\n",
            "error 2258.1103515625\n",
            "16 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 16687.796875\n",
            "16 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 12409.7734375\n",
            "16 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 17224.03125\n",
            "16 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 607.78955078125\n",
            "16 fc1\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 51402.1171875\n",
            "16 fc2\n",
            "Pruning ...\n",
            "time 1.83\n",
            "error 2242.6220703125\n",
            "17 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.53\n",
            "error 16041.1943359375\n",
            "17 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.49\n",
            "error 11793.869140625\n",
            "17 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.51\n",
            "error 16841.51953125\n",
            "17 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.58\n",
            "error 499.3668518066406\n",
            "17 fc1\n",
            "Pruning ...\n",
            "time 0.56\n",
            "error 49246.6953125\n",
            "17 fc2\n",
            "Pruning ...\n",
            "time 1.66\n",
            "error 2048.85498046875\n",
            "18 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 15098.4443359375\n",
            "18 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 11152.9365234375\n",
            "18 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 16194.404296875\n",
            "18 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 328.37286376953125\n",
            "18 fc1\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 46681.046875\n",
            "18 fc2\n",
            "Pruning ...\n",
            "time 1.59\n",
            "error 1858.880126953125\n",
            "19 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 14908.5546875\n",
            "19 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 9682.3125\n",
            "19 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 16083.3173828125\n",
            "19 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.40\n",
            "error 475.12176513671875\n",
            "19 fc1\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 44315.3515625\n",
            "19 fc2\n",
            "Pruning ...\n",
            "time 1.61\n",
            "error 1810.607666015625\n",
            "20 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 15789.228515625\n",
            "20 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 8766.4833984375\n",
            "20 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 16158.771484375\n",
            "20 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.41\n",
            "error 673.5532836914062\n",
            "20 fc1\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 44242.59375\n",
            "20 fc2\n",
            "Pruning ...\n",
            "time 1.62\n",
            "error 2135.2734375\n",
            "21 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 16189.90234375\n",
            "21 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 8680.47265625\n",
            "21 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 16590.361328125\n",
            "21 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.45\n",
            "error 632.8641967773438\n",
            "21 fc1\n",
            "Pruning ...\n",
            "time 0.53\n",
            "error 44770.61328125\n",
            "21 fc2\n",
            "Pruning ...\n",
            "time 2.27\n",
            "error 2913.9716796875\n",
            "22 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.58\n",
            "error 20983.982421875\n",
            "22 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 9524.3125\n",
            "22 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 19149.9921875\n",
            "22 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 1196.150634765625\n",
            "22 fc1\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 42623.625\n",
            "22 fc2\n",
            "Pruning ...\n",
            "time 1.63\n",
            "error 3213.79443359375\n",
            "23 self_attn.k_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 17697.98828125\n",
            "23 self_attn.v_proj\n",
            "Pruning ...\n",
            "time 0.37\n",
            "error 12906.955078125\n",
            "23 self_attn.q_proj\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 17089.361328125\n",
            "23 self_attn.out_proj\n",
            "Pruning ...\n",
            "time 0.38\n",
            "error 1225.9737548828125\n",
            "23 fc1\n",
            "Pruning ...\n",
            "time 0.39\n",
            "error 36082.71875\n",
            "23 fc2\n",
            "Pruning ...\n",
            "time 1.58\n",
            "error 2977.82080078125\n",
            "model.decoder.embed_tokens.weight tensor(5.8277e-07)\n",
            "model.decoder.embed_positions.weight tensor(0.0005)\n",
            "model.decoder.project_out.weight tensor(0.)\n",
            "model.decoder.project_in.weight tensor(0.)\n",
            "model.decoder.layers.0.self_attn.k_proj.weight tensor(0.0127)\n",
            "model.decoder.layers.0.self_attn.k_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.v_proj.weight tensor(0.1703)\n",
            "model.decoder.layers.0.self_attn.v_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.q_proj.weight tensor(0.0696)\n",
            "model.decoder.layers.0.self_attn.q_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn.out_proj.weight tensor(0.2513)\n",
            "model.decoder.layers.0.self_attn.out_proj.bias tensor(0.)\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight tensor(0.)\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias tensor(0.)\n",
            "model.decoder.layers.0.fc1.weight tensor(0.1587)\n",
            "model.decoder.layers.0.fc1.bias tensor(0.)\n",
            "model.decoder.layers.0.fc2.weight tensor(0.1761)\n",
            "387.0054507255554\n",
            "wikitext2\n",
            "Evaluating ...\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "Perplexity: 24.156233\n"
          ]
        }
      ],
      "source": [
        "!python  /content/spars_quant/Home\\ Work/HW\\ 1/sparsegpt/opt.py \\\n",
        "    --model /content/opt-350m \\\n",
        "    --dataset wikitext2 \\\n",
        "    --sparsity 0.0 \\\n",
        "    --wbits 4 \\\n",
        "    --save /content/weights/opt350m_gptq_w4_a16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args \"pretrained=/content/weights/opt350m_gptq_w4_a16\" \\\n",
        "    --tasks winogrande,boolq \\\n",
        "    --batch_size 4 \\\n",
        "    --num_fewshot 0 \\\n",
        "    --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpck_pvqO4Rs",
        "outputId": "6690a518-1810-45ad-890f-0ee5d585f359"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-12-01 17:42:50.256104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 17:42:50.275837: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 17:42:50.281819: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 17:42:50.296172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 17:42:51.485264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-12-01:17:42:53,440 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-12-01:17:43:03,791 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:17:43:03,820 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:17:43:04,110 INFO     [__main__.py:376] Selected Tasks: ['boolq', 'winogrande']\n",
            "2024-12-01:17:43:04,112 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
            "2024-12-01:17:43:04,112 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': '/content/weights/opt350m_gptq_w4_a16'}\n",
            "2024-12-01:17:43:04,171 INFO     [huggingface.py:129] Using device 'cuda'\n",
            "2024-12-01:17:43:04,173 INFO     [huggingface.py:481] Using model type 'default'\n",
            "2024-12-01:17:43:04,310 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
            "2024-12-01:17:43:05,078 WARNING  [task.py:799] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-12-01:17:43:05,079 WARNING  [task.py:811] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "2024-12-01:17:43:08,745 WARNING  [evaluator.py:270] Overwriting default num_fewshot of winogrande from None to 0\n",
            "2024-12-01:17:43:08,745 WARNING  [evaluator.py:270] Overwriting default num_fewshot of boolq from None to 0\n",
            "2024-12-01:17:43:08,745 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-12-01:17:43:08,747 INFO     [task.py:415] Building contexts for winogrande on rank 0...\n",
            "100% 1267/1267 [00:00<00:00, 82181.48it/s]\n",
            "2024-12-01:17:43:08,802 INFO     [task.py:415] Building contexts for boolq on rank 0...\n",
            "100% 3270/3270 [00:02<00:00, 1471.15it/s]\n",
            "2024-12-01:17:43:11,139 INFO     [evaluator.py:489] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 9074/9074 [02:49<00:00, 53.57it/s]\n",
            "2024-12-01:17:46:07,811 WARNING  [huggingface.py:1353] Failed to get model SHA for /content/weights/opt350m_gptq_w4_a16 at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/weights/opt350m_gptq_w4_a16'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2024-12-01:17:46:09,007 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated\n",
            "hf (pretrained=/content/weights/opt350m_gptq_w4_a16), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
            "|boolq     |      2|none  |     0|acc   |↑  |0.5920|±  |0.0086|\n",
            "|winogrande|      1|none  |     0|acc   |↑  |0.5185|±  |0.0140|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiucXEveX_8Y"
      },
      "source": [
        "## Метод спарсификации Wanda\n",
        "\n",
        "https://github.com/locuslab/wanda?tab=readme-ov-file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCSbCtjVYESS"
      },
      "source": [
        "Wanda - метод неструктурной спарсификации LLM, в котором ранжирование значимости весов $\\mathbf{W}$ каждого слоя модели выполняется посредством метрики:\n",
        "\n",
        "$\\begin{align}\n",
        "score(\\mathbf{W}) = \\lvert \\mathbf{W} \\rvert \\cdot \\lVert \\mathbf{X} \\rVert_{2},\n",
        "\\end{align}$\n",
        "где $\\lVert \\mathbf{X} \\rVert_{2}$ - усредненные по всем строкам посредством $L_{2}$ нормы значения активаций."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihs45jLtZOlX"
      },
      "source": [
        "<img src=\"https://github.com/iptkachev/Efficient-DL-Models/blob/master/Home%20Work/HW%201/notebooks/images/wanda.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBarOYhxFH1n"
      },
      "source": [
        "<em> Описание параметров </em>\n",
        "`model` - путь к директории, где хранится модель. <br>\n",
        "`prune_method` - метод спарсификации. <br>\n",
        "`sparsity_ratio` - коэффициент спарсификации, в интервале от 0.0 (оригинальная модель) до 1.0. <br>\n",
        "`sparsity_type` - тип спарсификации. <br>\n",
        "`save_model` - путь к директории, в которой будет сохранена модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNw6A9xd55ze",
        "outputId": "53c279ce-b561-416d-f155-b87f14b1cb01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "torch 2.5.1+cu121\n",
            "transformers 4.46.2\n",
            "accelerate 1.1.1\n",
            "# of gpus:  1\n",
            "loading llm model /content/opt-350m\n",
            "2024-12-01 17:46:17.224231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 17:46:17.255765: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 17:46:17.265559: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 17:46:17.287067: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 17:46:18.763406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "use device  cuda:0\n",
            "pruning starts\n",
            "loading calibdation data\n",
            "dataset loading complete\n",
            "pruning layer 0 name self_attn.k_proj\n",
            "pruning layer 0 name self_attn.v_proj\n",
            "pruning layer 0 name self_attn.q_proj\n",
            "pruning layer 0 name self_attn.out_proj\n",
            "pruning layer 0 name fc1\n",
            "pruning layer 0 name fc2\n",
            "pruning layer 1 name self_attn.k_proj\n",
            "pruning layer 1 name self_attn.v_proj\n",
            "pruning layer 1 name self_attn.q_proj\n",
            "pruning layer 1 name self_attn.out_proj\n",
            "pruning layer 1 name fc1\n",
            "pruning layer 1 name fc2\n",
            "pruning layer 2 name self_attn.k_proj\n",
            "pruning layer 2 name self_attn.v_proj\n",
            "pruning layer 2 name self_attn.q_proj\n",
            "pruning layer 2 name self_attn.out_proj\n",
            "pruning layer 2 name fc1\n",
            "pruning layer 2 name fc2\n",
            "pruning layer 3 name self_attn.k_proj\n",
            "pruning layer 3 name self_attn.v_proj\n",
            "pruning layer 3 name self_attn.q_proj\n",
            "pruning layer 3 name self_attn.out_proj\n",
            "pruning layer 3 name fc1\n",
            "pruning layer 3 name fc2\n",
            "pruning layer 4 name self_attn.k_proj\n",
            "pruning layer 4 name self_attn.v_proj\n",
            "pruning layer 4 name self_attn.q_proj\n",
            "pruning layer 4 name self_attn.out_proj\n",
            "pruning layer 4 name fc1\n",
            "pruning layer 4 name fc2\n",
            "pruning layer 5 name self_attn.k_proj\n",
            "pruning layer 5 name self_attn.v_proj\n",
            "pruning layer 5 name self_attn.q_proj\n",
            "pruning layer 5 name self_attn.out_proj\n",
            "pruning layer 5 name fc1\n",
            "pruning layer 5 name fc2\n",
            "pruning layer 6 name self_attn.k_proj\n",
            "pruning layer 6 name self_attn.v_proj\n",
            "pruning layer 6 name self_attn.q_proj\n",
            "pruning layer 6 name self_attn.out_proj\n",
            "pruning layer 6 name fc1\n",
            "pruning layer 6 name fc2\n",
            "pruning layer 7 name self_attn.k_proj\n",
            "pruning layer 7 name self_attn.v_proj\n",
            "pruning layer 7 name self_attn.q_proj\n",
            "pruning layer 7 name self_attn.out_proj\n",
            "pruning layer 7 name fc1\n",
            "pruning layer 7 name fc2\n",
            "pruning layer 8 name self_attn.k_proj\n",
            "pruning layer 8 name self_attn.v_proj\n",
            "pruning layer 8 name self_attn.q_proj\n",
            "pruning layer 8 name self_attn.out_proj\n",
            "pruning layer 8 name fc1\n",
            "pruning layer 8 name fc2\n",
            "pruning layer 9 name self_attn.k_proj\n",
            "pruning layer 9 name self_attn.v_proj\n",
            "pruning layer 9 name self_attn.q_proj\n",
            "pruning layer 9 name self_attn.out_proj\n",
            "pruning layer 9 name fc1\n",
            "pruning layer 9 name fc2\n",
            "pruning layer 10 name self_attn.k_proj\n",
            "pruning layer 10 name self_attn.v_proj\n",
            "pruning layer 10 name self_attn.q_proj\n",
            "pruning layer 10 name self_attn.out_proj\n",
            "pruning layer 10 name fc1\n",
            "pruning layer 10 name fc2\n",
            "pruning layer 11 name self_attn.k_proj\n",
            "pruning layer 11 name self_attn.v_proj\n",
            "pruning layer 11 name self_attn.q_proj\n",
            "pruning layer 11 name self_attn.out_proj\n",
            "pruning layer 11 name fc1\n",
            "pruning layer 11 name fc2\n",
            "pruning layer 12 name self_attn.k_proj\n",
            "pruning layer 12 name self_attn.v_proj\n",
            "pruning layer 12 name self_attn.q_proj\n",
            "pruning layer 12 name self_attn.out_proj\n",
            "pruning layer 12 name fc1\n",
            "pruning layer 12 name fc2\n",
            "pruning layer 13 name self_attn.k_proj\n",
            "pruning layer 13 name self_attn.v_proj\n",
            "pruning layer 13 name self_attn.q_proj\n",
            "pruning layer 13 name self_attn.out_proj\n",
            "pruning layer 13 name fc1\n",
            "pruning layer 13 name fc2\n",
            "pruning layer 14 name self_attn.k_proj\n",
            "pruning layer 14 name self_attn.v_proj\n",
            "pruning layer 14 name self_attn.q_proj\n",
            "pruning layer 14 name self_attn.out_proj\n",
            "pruning layer 14 name fc1\n",
            "pruning layer 14 name fc2\n",
            "pruning layer 15 name self_attn.k_proj\n",
            "pruning layer 15 name self_attn.v_proj\n",
            "pruning layer 15 name self_attn.q_proj\n",
            "pruning layer 15 name self_attn.out_proj\n",
            "pruning layer 15 name fc1\n",
            "pruning layer 15 name fc2\n",
            "pruning layer 16 name self_attn.k_proj\n",
            "pruning layer 16 name self_attn.v_proj\n",
            "pruning layer 16 name self_attn.q_proj\n",
            "pruning layer 16 name self_attn.out_proj\n",
            "pruning layer 16 name fc1\n",
            "pruning layer 16 name fc2\n",
            "pruning layer 17 name self_attn.k_proj\n",
            "pruning layer 17 name self_attn.v_proj\n",
            "pruning layer 17 name self_attn.q_proj\n",
            "pruning layer 17 name self_attn.out_proj\n",
            "pruning layer 17 name fc1\n",
            "pruning layer 17 name fc2\n",
            "pruning layer 18 name self_attn.k_proj\n",
            "pruning layer 18 name self_attn.v_proj\n",
            "pruning layer 18 name self_attn.q_proj\n",
            "pruning layer 18 name self_attn.out_proj\n",
            "pruning layer 18 name fc1\n",
            "pruning layer 18 name fc2\n",
            "pruning layer 19 name self_attn.k_proj\n",
            "pruning layer 19 name self_attn.v_proj\n",
            "pruning layer 19 name self_attn.q_proj\n",
            "pruning layer 19 name self_attn.out_proj\n",
            "pruning layer 19 name fc1\n",
            "pruning layer 19 name fc2\n",
            "pruning layer 20 name self_attn.k_proj\n",
            "pruning layer 20 name self_attn.v_proj\n",
            "pruning layer 20 name self_attn.q_proj\n",
            "pruning layer 20 name self_attn.out_proj\n",
            "pruning layer 20 name fc1\n",
            "pruning layer 20 name fc2\n",
            "pruning layer 21 name self_attn.k_proj\n",
            "pruning layer 21 name self_attn.v_proj\n",
            "pruning layer 21 name self_attn.q_proj\n",
            "pruning layer 21 name self_attn.out_proj\n",
            "pruning layer 21 name fc1\n",
            "pruning layer 21 name fc2\n",
            "pruning layer 22 name self_attn.k_proj\n",
            "pruning layer 22 name self_attn.v_proj\n",
            "pruning layer 22 name self_attn.q_proj\n",
            "pruning layer 22 name self_attn.out_proj\n",
            "pruning layer 22 name fc1\n",
            "pruning layer 22 name fc2\n",
            "pruning layer 23 name self_attn.k_proj\n",
            "pruning layer 23 name self_attn.v_proj\n",
            "pruning layer 23 name self_attn.q_proj\n",
            "pruning layer 23 name self_attn.out_proj\n",
            "pruning layer 23 name fc1\n",
            "pruning layer 23 name fc2\n",
            "******************************\n",
            "layer 0 sparsity 0.500000\n",
            "layer 1 sparsity 0.500000\n",
            "layer 2 sparsity 0.500000\n",
            "layer 3 sparsity 0.500000\n",
            "layer 4 sparsity 0.500000\n",
            "layer 5 sparsity 0.500000\n",
            "layer 6 sparsity 0.500000\n",
            "layer 7 sparsity 0.500000\n",
            "layer 8 sparsity 0.500000\n",
            "layer 9 sparsity 0.500000\n",
            "layer 10 sparsity 0.500000\n",
            "layer 11 sparsity 0.500000\n",
            "layer 12 sparsity 0.500000\n",
            "layer 13 sparsity 0.500000\n",
            "layer 14 sparsity 0.500000\n",
            "layer 15 sparsity 0.500000\n",
            "layer 16 sparsity 0.500000\n",
            "layer 17 sparsity 0.500000\n",
            "layer 18 sparsity 0.500000\n",
            "layer 19 sparsity 0.500000\n",
            "layer 20 sparsity 0.500000\n",
            "layer 21 sparsity 0.500000\n",
            "layer 22 sparsity 0.500000\n",
            "layer 23 sparsity 0.500000\n",
            "sparsity sanity check 0.5000\n",
            "******************************\n",
            "evaluating on wikitext2\n",
            "nsamples 140\n",
            "sample 0\n",
            "sample 50\n",
            "sample 100\n",
            "wikitext perplexity 35.3378791809082\n"
          ]
        }
      ],
      "source": [
        "!python /content/spars_quant/Home\\ Work/HW\\ 1/wanda/main_opt.py \\\n",
        "    --model /content/opt-350m \\\n",
        "    --prune_method wanda \\\n",
        "    --sparsity_ratio 0.5 \\\n",
        "    --sparsity_type unstructured \\\n",
        "    --save_model /content/weight/opt350m_wanda_50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aOg0GOv55s7",
        "outputId": "e0fcd4f7-0a1c-45d8-8bbc-3ed3ea96b68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2024-12-01 17:53:28.185422: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-01 17:53:28.218591: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-01 17:53:28.228906: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-01 17:53:28.253108: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-01 17:53:29.496576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-12-01:17:53:31,432 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-12-01:17:53:41,591 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:17:53:41,641 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
            "2024-12-01:17:53:42,114 INFO     [__main__.py:376] Selected Tasks: ['boolq', 'winogrande']\n",
            "2024-12-01:17:53:42,115 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
            "2024-12-01:17:53:42,115 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': '/content/weight/opt350m_wanda_50'}\n",
            "2024-12-01:17:53:42,173 INFO     [huggingface.py:129] Using device 'cuda'\n",
            "2024-12-01:17:53:42,175 INFO     [huggingface.py:481] Using model type 'default'\n",
            "2024-12-01:17:53:42,311 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
            "2024-12-01:17:53:43,100 WARNING  [task.py:799] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
            "2024-12-01:17:53:43,100 WARNING  [task.py:811] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
            "2024-12-01:17:53:46,820 WARNING  [evaluator.py:270] Overwriting default num_fewshot of winogrande from None to 0\n",
            "2024-12-01:17:53:46,821 WARNING  [evaluator.py:270] Overwriting default num_fewshot of boolq from None to 0\n",
            "2024-12-01:17:53:46,821 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-12-01:17:53:46,823 INFO     [task.py:415] Building contexts for winogrande on rank 0...\n",
            "100% 1267/1267 [00:00<00:00, 86260.81it/s]\n",
            "2024-12-01:17:53:46,893 INFO     [task.py:415] Building contexts for boolq on rank 0...\n",
            "100% 3270/3270 [00:01<00:00, 1837.83it/s]\n",
            "2024-12-01:17:53:48,788 INFO     [evaluator.py:489] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 9074/9074 [02:48<00:00, 53.89it/s]\n",
            "2024-12-01:17:56:44,917 WARNING  [huggingface.py:1353] Failed to get model SHA for /content/weight/opt350m_wanda_50 at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/weight/opt350m_wanda_50'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2024-12-01:17:56:46,519 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated\n",
            "hf (pretrained=/content/weight/opt350m_wanda_50), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
            "|boolq     |      2|none  |     0|acc   |↑  |0.4933|±  |0.0087|\n",
            "|winogrande|      1|none  |     0|acc   |↑  |0.5004|±  |0.0141|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args \"pretrained=/content/weight/opt350m_wanda_50\" \\\n",
        "    --tasks winogrande,boolq \\\n",
        "    --batch_size 4 \\\n",
        "    --num_fewshot 0 \\\n",
        "    --device cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uA0R5dm8in9"
      },
      "source": [
        "# Ваши графики и решения тут:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def parse_text_table(table_text: str):\n",
        "  df = pd.read_csv(io.StringIO(table_text), sep='|', skiprows=[1], skipinitialspace=True)\n",
        "  df = df.drop(df.columns[[0, 2, 3, 4, 5, 6, 8, 10]], axis=1)\n",
        "  df.columns = [col.strip() for col in df.columns]\n",
        "  df['Tasks'] = df['Tasks'].str.strip()\n",
        "  df['Value'] = df['Value'].astype(float)\n",
        "  df['Stderr'] = df['Stderr'].astype(float)\n",
        "  return df"
      ],
      "metadata": {
        "id": "HZxinJZAf1zY"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_data = {\n",
        "    \"baseline\": \"\"\"|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
        "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
        "|boolq     |      2|none  |     0|acc   |↑  |0.5771|±  |0.0086|\n",
        "|winogrande|      1|none  |     0|acc   |↑  |0.5225|±  |0.0140|\"\"\",\n",
        "    \"quik_w4_a16\": \"\"\"|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
        "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
        "|boolq     |      2|none  |     0|acc   |↑  |0.5651|±  |0.0087|\n",
        "|winogrande|      1|none  |     0|acc   |↑  |0.5296|±  |0.0140|\"\"\",\n",
        "    \"sparsegpt_50_w16_a16\": \"\"\"|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
        "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
        "|boolq     |      2|none  |     0|acc   |↑  |0.5933|±  |0.0086|\n",
        "|winogrande|      1|none  |     0|acc   |↑  |0.5122|±  |0.0140|\"\"\",\n",
        "    \"gptq_w4_a16\": \"\"\"|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
        "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
        "|boolq     |      2|none  |     0|acc   |↑  |0.5920|±  |0.0086|\n",
        "|winogrande|      1|none  |     0|acc   |↑  |0.5185|±  |0.0140|\"\"\",\n",
        "    \"wanda_50\": \"\"\"|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
        "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
        "|boolq     |      2|none  |     0|acc   |↑  |0.4933|±  |0.0087|\n",
        "|winogrande|      1|none  |     0|acc   |↑  |0.5004|±  |0.0141|\"\"\"\n",
        "}"
      ],
      "metadata": {
        "id": "MWsN3d0iTDve"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "union_table = []\n",
        "for model, text_df in analysis_data.items():\n",
        "  parsed_df = parse_text_table(text_df)\n",
        "  parsed_df[\"model\"] = model\n",
        "  union_table.append(parsed_df)\n",
        "\n",
        "union_table = pd.concat(union_table, axis=0)"
      ],
      "metadata": {
        "id": "vXtBWRLUf58C"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "union_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "yDHNh5UEiRPB",
        "outputId": "46830d61-53f7-4f77-db8a-6e9ed5db72b1"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Tasks   Value  Stderr                 model\n",
              "0       boolq  0.5771  0.0086              baseline\n",
              "1  winogrande  0.5225  0.0140              baseline\n",
              "0       boolq  0.5651  0.0087           quik_w4_a16\n",
              "1  winogrande  0.5296  0.0140           quik_w4_a16\n",
              "0       boolq  0.5933  0.0086  sparsegpt_50_w16_a16\n",
              "1  winogrande  0.5122  0.0140  sparsegpt_50_w16_a16\n",
              "0       boolq  0.5920  0.0086           gptq_w4_a16\n",
              "1  winogrande  0.5185  0.0140           gptq_w4_a16\n",
              "0       boolq  0.4933  0.0087              wanda_50\n",
              "1  winogrande  0.5004  0.0141              wanda_50"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2edf9612-6646-4520-8cef-58aaba1d9bf6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tasks</th>\n",
              "      <th>Value</th>\n",
              "      <th>Stderr</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>boolq</td>\n",
              "      <td>0.5771</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>baseline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>winogrande</td>\n",
              "      <td>0.5225</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>baseline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>boolq</td>\n",
              "      <td>0.5651</td>\n",
              "      <td>0.0087</td>\n",
              "      <td>quik_w4_a16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>winogrande</td>\n",
              "      <td>0.5296</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>quik_w4_a16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>boolq</td>\n",
              "      <td>0.5933</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>sparsegpt_50_w16_a16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>winogrande</td>\n",
              "      <td>0.5122</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>sparsegpt_50_w16_a16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>boolq</td>\n",
              "      <td>0.5920</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>gptq_w4_a16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>winogrande</td>\n",
              "      <td>0.5185</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>gptq_w4_a16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>boolq</td>\n",
              "      <td>0.4933</td>\n",
              "      <td>0.0087</td>\n",
              "      <td>wanda_50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>winogrande</td>\n",
              "      <td>0.5004</td>\n",
              "      <td>0.0141</td>\n",
              "      <td>wanda_50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2edf9612-6646-4520-8cef-58aaba1d9bf6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2edf9612-6646-4520-8cef-58aaba1d9bf6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2edf9612-6646-4520-8cef-58aaba1d9bf6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3cb748f-d6ce-4e91-b57e-a91254ed41af\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3cb748f-d6ce-4e91-b57e-a91254ed41af')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3cb748f-d6ce-4e91-b57e-a91254ed41af button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "union_table",
              "summary": "{\n  \"name\": \"union_table\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Tasks\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"winogrande\",\n          \"boolq\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03793014046316671,\n        \"min\": 0.4933,\n        \"max\": 0.5933,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.4933,\n          0.5225\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stderr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0028359007975127296,\n        \"min\": 0.0086,\n        \"max\": 0.0141,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.014,\n          0.0141\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"quik_w4_a16\",\n          \"wanda_50\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "sns.barplot(x=\"model\", y=\"Value\", data=union_table[union_table.Tasks == 'boolq'], ax=axes[0])\n",
        "sns.barplot(x=\"model\", y=\"Value\", data=union_table[union_table.Tasks == 'winogrande'], ax=axes[1])\n",
        "for ax in axes:\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='right');\n",
        "\n",
        "axes[0].set_title('boolq')\n",
        "axes[1].set_title('winogrande')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "mFZpipAAi2yv",
        "outputId": "d039c6f7-3088-4719-f597-27ed8a770870"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-144-74ba27e8165f>:5: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='right');\n",
            "<ipython-input-144-74ba27e8165f>:5: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='right');\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'winogrande')"
            ]
          },
          "metadata": {},
          "execution_count": 144
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(11, 6))\n",
        "avg_acc = union_table.groupby(\"model\", as_index=False)[\"Value\"].mean()\n",
        "plt.grid()\n",
        "sns.barplot(x=\"model\", y=\"Value\", data=avg_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "rl_VqjrTke5T",
        "outputId": "221375b6-09fe-41eb-ddd2-dbe2895a1c60"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='model', ylabel='Value'>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1100x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "juDGeQCZo7HN",
        "outputId": "94939eb0-1499-4d8d-92de-693ff33a4de9"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  model    Value\n",
              "0              baseline  0.54980\n",
              "1           gptq_w4_a16  0.55525\n",
              "2           quik_w4_a16  0.54735\n",
              "3  sparsegpt_50_w16_a16  0.55275\n",
              "4              wanda_50  0.49685"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a4fb717-4177-47c9-b8d2-a9e81c55c982\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>0.54980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gptq_w4_a16</td>\n",
              "      <td>0.55525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>quik_w4_a16</td>\n",
              "      <td>0.54735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sparsegpt_50_w16_a16</td>\n",
              "      <td>0.55275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wanda_50</td>\n",
              "      <td>0.49685</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a4fb717-4177-47c9-b8d2-a9e81c55c982')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9a4fb717-4177-47c9-b8d2-a9e81c55c982 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9a4fb717-4177-47c9-b8d2-a9e81c55c982');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-08f36844-f6f5-446d-8012-cc6fa7cd36e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08f36844-f6f5-446d-8012-cc6fa7cd36e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-08f36844-f6f5-446d-8012-cc6fa7cd36e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "avg_acc",
              "summary": "{\n  \"name\": \"avg_acc\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"gptq_w4_a16\",\n          \"wanda_50\",\n          \"quik_w4_a16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.024527076874344404,\n        \"min\": 0.49685,\n        \"max\": 0.55525,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.55525,\n          0.49685,\n          0.54735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод по результатам анализа:\n"
      ],
      "metadata": {
        "id": "OPv8svA9o2Aj"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}